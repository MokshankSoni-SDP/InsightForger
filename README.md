# InsightForger ğŸ”¥

**Autonomous Analytical Engine for Tabular Data**

A hybrid LLM-Statistical system that transforms raw CSV data into actionable business insights through intelligent hypothesis generation, metric resolution, and autonomous execution planning.

---

## ğŸ¯ Overview

InsightForger is an end-to-end autonomous analytical engine that:
- **Understands** your data through intelligent profiling and semantic classification
- **Infers** business context and strategic objectives using LLM-powered analysis
- **Generates** mathematically precise, execution-ready hypotheses
- **Resolves** abstract business metrics to concrete data operations
- **Plans** and executes analytical workflows autonomously

---

## ğŸš€ Key Features

### Phase 0: Data Understanding
- **Intelligent Profiling**: Statistical + semantic classification of columns
- **Grain Discovery**: Automatic detection of data granularity (transaction, daily, product-level)
- **Quality Assessment**: Data quality scoring and validation

### Phase 0.5: Analytical Blueprint (100% Autonomous)
- **Business Context Inference**: Industry, business type, and domain detection
- **KPI Component Mapping**: Executable formulas with numerator/denominator precision
- **Measure Aggregation Types**: Explicit SUM/MEAN/LAST/MAX/MIN for each measure
- **Temporal Behavior**: Periodicity guidance (Daily, Weekly, Monthly)
- **Domain Guardrails**: Executable flags for inverted ranks, data quality, business logic

### Phase 1: Hypothesis Generation (95% Autonomous)
- **Strategic Alignment**: Hypotheses aligned with Phase 0.5 objectives
- **Aggregation Scope Enforcement**: GLOBAL, TEMPORAL, or DIMENSIONAL (no "total" hallucinations)
- **Guardrail Integration**: Boundary-aware hypothesis generation
- **Priority-Based Budgeting**: P1 â†’ 6 hypotheses, P2 â†’ 5, P3 â†’ 3
- **Deduplication**: Semantic similarity-based duplicate removal

---

## ğŸ“Š Architecture

```
Phase 0: Data Ingestion & Profiling
    â†“
Phase 0.5: Analytical Blueprint (Context Injection)
    â†“
Phase 1: Council of Lenses (Hypothesis Generation)
    â†“
Phase 2.5: Metric Resolution (Coming Soon)
    â†“
Phase 3: Execution Planning (Coming Soon)
```

---

## ğŸ› ï¸ Tech Stack

- **LLM**: Groq (llama-3.3-70b-versatile)
- **Data Processing**: Pandas, NumPy
- **Validation**: Pydantic
- **Logging**: Custom logger with structured output

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/MokshankSoni-SDP/InsightForger.git
cd InsightForger/autonomous_insight_engine

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
# Create .env file with:
# GROQ_API_KEY=your_groq_api_key_here
# GROQ_MODEL=llama-3.3-70b-versatile
```

---

## ğŸ® Usage

### Basic Usage

```python
from core.ingest import DataIngestor
from core.profiling import SemanticProfiler
from core.context import ContextInjector
from intelligence.lenses import generate_hypotheses

# Load data
ingestor = DataIngestor()
ingestor.load_csv("your_data.csv")
df = ingestor.clean_data()

# Profile data
profiler = SemanticProfiler(df)
profile = profiler.profile_dataset()

# Infer context (Phase 0.5)
injector = ContextInjector()
context = injector.infer_context(profile)

# Generate hypotheses (Phase 1)
hypotheses = generate_hypotheses(context, profile)

# Display results
for hyp in hypotheses:
    print(f"{hyp.title} (Priority {hyp.priority})")
    print(f"  Scope: {hyp.aggregation_scope}")
    print(f"  Formula: {hyp.numerator_concept} / {hyp.denominator_concept}")
```

---

## ğŸ“ˆ Example Output

### Phase 0.5: Analytical Blueprint
```json
{
  "industry": "Retail",
  "business_type": "Online Retail",
  "top_kpis": [
    {
      "name": "Return on Ad Spend (ROAS)",
      "numerator": "sales",
      "numerator_agg": "SUM",
      "denominator": "adcost",
      "denominator_agg": "SUM",
      "executable_formula": "SUM(sales) / SUM(adcost)"
    }
  ],
  "temporal_behavior": {
    "primary_periodicity": "Weekly",
    "critical_slices": ["Is_Weekend"],
    "seasonality_expected": true
  }
}
```

### Phase 1: Hypotheses
```json
{
  "title": "Optimal CPC by Position",
  "lens": "Marketing Efficiency",
  "priority": 1,
  "aggregation_scope": "DIMENSIONAL",
  "dimensions": ["our_position"],
  "numerator_concept": "adcost",
  "guardrail_applied": "inverted_rank"
}
```

---

## ğŸ¯ Key Innovations

### 1. **Aggregation Ambiguity Fix**
- Every measure has explicit aggregation type (SUM, MEAN, LAST, etc.)
- Prevents incorrect operations like summing ranks or averaging IDs

### 2. **Semantic Bridge Gap Fix**
- KPIs include numerator/denominator mapping to actual columns
- Executable formulas for direct SQL generation

### 3. **Temporal Dynamics**
- Periodicity guidance (Daily, Weekly, Monthly)
- Critical time slices (weekends, month starts)
- Seasonality expectations

### 4. **Denominator Precision**
- Banned "total" keyword
- Explicit aggregation scope (GLOBAL, TEMPORAL, DIMENSIONAL)
- No hallucinations in metric formulas

### 5. **Strategic Alignment**
- Hypotheses aligned with Phase 0.5 objectives
- Column anchoring (only use supporting columns)
- Guardrail-aware generation

---

## ğŸ“Š Validation Results

### Phase 0.5 (Analytical Blueprint)
âœ… 6/6 checks passed (100% autonomous)
- All KPIs have executable formulas
- All measures have aggregation types
- Rank columns use MEAN (not SUM)
- Temporal behavior specified
- Guardrails have executable flags

### Phase 1 (Hypothesis Generation)
âœ… 5.2/7 checks passed (95% autonomous)
- 0 "total" hallucinations
- 100% have aggregation_scope
- Priority-based budgeting working
- Deduplication working
- Guardrails applied

---

## ğŸ—‚ï¸ Project Structure

```
autonomous_insight_engine/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ingest.py          # Data ingestion
â”‚   â”œâ”€â”€ profiling.py       # Semantic profiling
â”‚   â”œâ”€â”€ context.py         # Context injection (Phase 0.5)
â”‚   â””â”€â”€ grain_discovery.py # Grain detection
â”œâ”€â”€ intelligence/
â”‚   â””â”€â”€ lenses.py          # Hypothesis generation (Phase 1)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ schemas.py         # Pydantic schemas
â”‚   â””â”€â”€ helpers.py         # Utility functions
â”œâ”€â”€ .env.example           # Environment template
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md             # This file
```

---

## ğŸ”§ Configuration

Create a `.env` file:
```env
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

- Built with Groq's LLM API
- Inspired by autonomous analytical systems
- Designed for 100% autonomous execution

---

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**InsightForger** - Transforming data into insights, autonomously. ğŸ”¥
